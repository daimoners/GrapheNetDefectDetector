{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lib.lib_utils import Utils\n",
    "    import seaborn as sns\n",
    "    from lib.lib_defect_analysis import Features\n",
    "    from tqdm import tqdm\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from sklearn import ensemble\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import scipy\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from tqdm import tqdm\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "except Exception as e:\n",
    "    print(f\"Some module are missing: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path().resolve().joinpath(\"data\")\n",
    "xyz_files_path = data_path.joinpath(\"xyz_files\")\n",
    "yolo_model_path = data_path.joinpath(\"models\", \"best.pt\")\n",
    "images_path = data_path.joinpath(\"images\")\n",
    "crops_path = data_path.joinpath(\"crops\")\n",
    "plot_path = Path().cwd().joinpath('plots')\n",
    "pred_path = Path().cwd().joinpath('predictions')\n",
    "plot_path.mkdir(exist_ok=True, parents=True)\n",
    "pred_path.mkdir(exist_ok=True, parents=True)\n",
    "plt.style.use(\"seaborn-v0_8-paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: the directory /home/mario/Mario/Phd_code/GDD/GrapheNetDefectDetector/data/images already exists!\n",
      "WARNING: the directory /home/mario/Mario/Phd_code/GDD/GrapheNetDefectDetector/data/crops already exists!\n"
     ]
    }
   ],
   "source": [
    "max_dim = [39.53476932, 34.27629786]\n",
    "Utils.from_xyz_to_png(xyz_files_path, images_path, max_dim=max_dim, multiplier=6)\n",
    "\n",
    "Utils.generate_yolo_crops(\n",
    "    images_path, crops_path, yolo_model_path, binary_mask=True, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = data_path.joinpath(\"features.csv\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not filepath:\n",
    "    images = [\n",
    "        f for f in crops_path.iterdir() if f.suffix.lower() in Features.IMAGE_EXTENSIONS\n",
    "    ]\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    for image in tqdm(images):\n",
    "        if len(features) == 0:\n",
    "            keys_list = list(features.keys())\n",
    "            df = pd.DataFrame(columns=keys_list)\n",
    "        else:\n",
    "            features.clear()\n",
    "\n",
    "        name = image.stem.split(\"_crop\")[0]\n",
    "\n",
    "        with open(str(xyz_files_path.joinpath(f\"{name}.xyz\")), \"r\") as file:\n",
    "            first_line = file.readline()\n",
    "        n_atoms = int(first_line.strip())\n",
    "\n",
    "        features.update({\"file_name\": name})\n",
    "        features.update({\"n_atoms\": n_atoms})\n",
    "\n",
    "        shape_features = Features.extract_shape_features(image, grayscale=True)\n",
    "        if shape_features is not None:\n",
    "            features.update(shape_features)\n",
    "\n",
    "        edge_features = Features.extract_edge_features(image, grayscale=True)\n",
    "        if edge_features is not None:\n",
    "            features.update(edge_features)\n",
    "\n",
    "        texture_features = Features.extract_texture_features(image)\n",
    "        if texture_features is not None:\n",
    "            features.update(texture_features)\n",
    "\n",
    "        new_row = pd.Series(features)\n",
    "        df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "    grouped_df = (\n",
    "        df.groupby(\"file_name\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"n_atoms\": \"first\",\n",
    "                \"area\": \"sum\",\n",
    "                \"num_pixels\": \"sum\",\n",
    "                \"perimeter\": \"sum\",\n",
    "                \"circularity\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"solidity\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"compactness\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"feret_diameter\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"eccentricity\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"number_of_edges\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"edge_density\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"edge_density\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"GLCM_contrast\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"GLCM_homogeneity\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"GLCM_energy\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "                \"GLCM_correlation\": lambda x: (x * df.loc[x.index, \"area\"]).sum()\n",
    "                / df.loc[x.index, \"area\"].sum(),\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    #\n",
    "    original_df = pd.read_csv(xyz_files_path.joinpath(\"target_graphene_dftb.csv\"))\n",
    "\n",
    "    energy_dict = original_df.set_index(\"file_name\")[\"total_energy_eV\"].to_dict()\n",
    "    fermi_dict = original_df.set_index(\"file_name\")[\"fermi_level_ev\"].to_dict()\n",
    "    ip_dict = original_df.set_index(\"file_name\")[\"IP_ev\"].to_dict()\n",
    "    ea_dict = original_df.set_index(\"file_name\")[\"EA_ev\"].to_dict()\n",
    "    band_gap_dict = original_df.set_index(\"file_name\")[\"band_gap_ev\"].to_dict()\n",
    "\n",
    "    # Aggiunta della colonna total_energy al primo dataframe\n",
    "    grouped_df[\"total_energy_eV\"] = grouped_df[\"file_name\"].map(energy_dict)\n",
    "    grouped_df[\"fermi_level_ev\"] = grouped_df[\"file_name\"].map(fermi_dict)\n",
    "    grouped_df[\"IP_ev\"] = grouped_df[\"file_name\"].map(ip_dict)\n",
    "    grouped_df[\"EA_ev\"] = grouped_df[\"file_name\"].map(ea_dict)\n",
    "    grouped_df[\"band_gap_ev\"] = grouped_df[\"file_name\"].map(band_gap_dict)\n",
    "    grouped_df[\"energy_per_atom\"] = (\n",
    "        grouped_df[\"total_energy_eV\"] / grouped_df[\"n_atoms\"]\n",
    "    )\n",
    "    grouped_df = grouped_df.dropna()\n",
    "\n",
    "    grouped_df.to_csv(data_path.joinpath(\"features.csv\"), index=False)\n",
    "else:\n",
    "    grouped_df = pd.read_csv(data_path.joinpath(\"features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il DataFrame non contiene valori NaN.\n"
     ]
    }
   ],
   "source": [
    "if grouped_df.isna().any().any():\n",
    "    print(\"Avviso: Il DataFrame contiene valori NaN.\")\n",
    "else:\n",
    "    print(\"Il DataFrame non contiene valori NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2717399378.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    In [ ]:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "features_list = [\n",
    "    \"area\",\n",
    "    \"perimeter\",\n",
    "    \"circularity\",\n",
    "    \"solidity\",\n",
    "    \"feret_diameter\",\n",
    "    \"compactness\",\n",
    "    \"eccentricity\",\n",
    "    \"number_of_edges\",\n",
    "    \"edge_density\",\n",
    "    \"GLCM_correlation\",\n",
    "    \"GLCM_energy\",\n",
    "    \"GLCM_homogeneity\",\n",
    "    \"GLCM_contrast\",\n",
    "]\n",
    "res = 231 * 199\n",
    "df_filtrato = grouped_df[grouped_df[\"area\"] / res < 0.3]\n",
    "for feature in features_list:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    sns.histplot(df_filtrato[feature], kde=True, bins=int(np.sqrt(len(grouped_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    "    \"area\",\n",
    "    \"perimeter\",\n",
    "    \"circularity\",\n",
    "    \"solidity\",\n",
    "    \"feret_diameter\",\n",
    "    \"compactness\",\n",
    "    \"eccentricity\",\n",
    "    \"number_of_edges\",\n",
    "    \"edge_density\",\n",
    "    \"GLCM_correlation\",\n",
    "    \"GLCM_energy\",\n",
    "    \"GLCM_homogeneity\",\n",
    "    \"GLCM_contrast\",\n",
    "]\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 2770,\n",
    "    \"learning_rate\": 0.010562915246990538,\n",
    "    \"max_depth\": 10,\n",
    "    \"gamma\": 0.0002985546393874009,\n",
    "    \"min_child_weight\": 1.8685613953859606,\n",
    "    \"colsample_bytree\": 0.9633894246849674,\n",
    "    \"subsample\": 0.5195778253826636,\n",
    "}\n",
    "model = xgb.XGBRegressor(**params)\n",
    "target_list = [\n",
    "    \"fermi_level_ev\",\n",
    "    \"IP_ev\",\n",
    "    \"EA_ev\",\n",
    "    \"band_gap_ev\",\n",
    "    \"energy_per_atom\",\n",
    "    # \"total_energy_eV\",\n",
    "]\n",
    "grouped_df = df_filtrato.copy()\n",
    "X = grouped_df[features_list].values\n",
    "scores = []\n",
    "for target in tqdm(target_list):\n",
    "    target_scores = []\n",
    "    file_names = grouped_df[\"file_name\"]\n",
    "    y = grouped_df[target].values.flatten()\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #     X, y, test_size=0.2, random_state=3333\n",
    "    # )\n",
    "    combined = list(zip(X, y, file_names))\n",
    "    # Splittare combined\n",
    "    train, test = train_test_split(combined, test_size=0.2, random_state=3333)\n",
    "\n",
    "    # Separare X, y e file_names per train e test\n",
    "    X_train, y_train, file_names_train = zip(*train)\n",
    "    X_test, y_test, file_names_test = zip(*test)\n",
    "\n",
    "    # Convertire in array numpy per l'utilizzo con scikit-learn\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    residual_error = y_test - y_pred\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            f\"{target}_predicted\": y_pred,\n",
    "            f\"{target}_real\": y_test,\n",
    "            f\"{target}_residual\": residual_error,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Salvataggio del DataFrame in un CSV\n",
    "    results_df.to_csv(pred_path.joinpath(f\"{target}_predictions.csv\"), index=False)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    scores.append([mse, mae, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_array = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(target_list, scores_array[:, 0])\n",
    "plt.ylabel(\"mean sqaured error\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(target_list, scores_array[:, 1])\n",
    "plt.ylabel(\"mean absolute error\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(target_list, scores_array[:, 2])\n",
    "plt.ylabel(\"R2 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors =[\"#ED4638\",\"#0A2C52\"]\n",
    "# colors = [\"#CE4F38\", \"#1D5CAF\"]\n",
    "colors = [\"#F0741E\", \"#276CB3\"]\n",
    "target_labels = {\n",
    "    \"fermi_level_ev\": (\"Fermi Level [eV] - predicted\", \"Fermi Level[eV] - true\"),\n",
    "    \"EA_ev\": (\"Electron Affinity [eV] - predicted\", \"Electron Affinity [eV] - true\"),\n",
    "    \"IP_ev\": (\n",
    "        \"Ionization Potential [eV] - predicted\",\n",
    "        \"Ionization Potential [eV] - true\",\n",
    "    ),\n",
    "    \"band_gap_ev\": (\"Band Gap [eV] - predicted\", \"Band Gap [eV] - true\"),\n",
    "    \"energy_per_atom\": (\n",
    "        \"Energy Per Atom [eV] - predicted\",\n",
    "        \"Energy Per Atom [eV] - true\",\n",
    "    ),\n",
    "}\n",
    "for target in target_list:\n",
    "    df = pd.read_csv(pred_path.joinpath(f'{target}_predictions.csv'), header=0)\n",
    "\n",
    "\n",
    "    MAX = np.max(\n",
    "        [df[f\"{target}_predicted\"].to_numpy(), df[f\"{target}_real\"].to_numpy()]\n",
    "    )\n",
    "    MIN = np.min(\n",
    "        [df[f\"{target}_predicted\"].to_numpy(), df[f\"{target}_real\"].to_numpy()]\n",
    "    )\n",
    "\n",
    "    offset = 0.05 * np.abs(MAX - MIN)\n",
    "    bound = [MIN - offset, MAX + offset]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    g = sns.JointGrid()\n",
    "    x, y = df[f\"{target}_predicted\"], df[f\"{target}_real\"]\n",
    "    sns.regplot(\n",
    "        x=f\"{target}_predicted\",\n",
    "        y=f\"{target}_real\",\n",
    "        data=df,\n",
    "        ax=g.ax_joint,\n",
    "        scatter_kws={\"s\": 40, \"alpha\": 0.5, \"color\": colors[1]},\n",
    "        line_kws={\"linewidth\": 3, \"alpha\": 1, \"color\": colors[0]},\n",
    "    )\n",
    "    sns.histplot(\n",
    "        x=x,\n",
    "        fill=True,\n",
    "        linewidth=1,\n",
    "        kde=False,\n",
    "        ax=g.ax_marg_x,\n",
    "        stat=\"density\",\n",
    "        color=colors[1],\n",
    "    )\n",
    "    sns.kdeplot(x=x, linewidth=2, ax=g.ax_marg_x, color=colors[0])\n",
    "    sns.histplot(\n",
    "        y=y,\n",
    "        fill=True,\n",
    "        linewidth=1,\n",
    "        kde=False,\n",
    "        ax=g.ax_marg_y,\n",
    "        stat=\"density\",\n",
    "        color=colors[1],\n",
    "    )\n",
    "    sns.kdeplot(y=y, linewidth=2, ax=g.ax_marg_y, color=colors[0])\n",
    "    # g.ax_joint.set_xticks(ticks)\n",
    "    # g.ax_joint.set_yticks(ticks)\n",
    "    g.ax_joint.set_xlim(bound)\n",
    "    g.ax_joint.set_ylim(bound)\n",
    "    g.ax_joint.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "    g.ax_joint.xaxis.set_major_locator(MaxNLocator(nbins=3))  # Auto tick locator\n",
    "    g.ax_joint.yaxis.set_major_locator(MaxNLocator(nbins=3))  #\n",
    "    g.set_axis_labels(\n",
    "        target_labels[f\"{target}\"][0], target_labels[f\"{target}\"][1], fontsize=20\n",
    "    )\n",
    "\n",
    "    plt.savefig(plot_path.joinpath(f\"{target}_fit.png\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = {\n",
    "    \"fermi_level_ev\": (\"Fermi Level [eV] - Residual Errors\", \"Density of Residuals\"),\n",
    "    \"EA_ev\": (\"Electron Affinity [eV] - Residual Errors\", \"Density of Residuals\"),\n",
    "    \"IP_ev\": (\n",
    "        \"Ionization Potential [eV] - Residual Errors\",\n",
    "        \"Density of Residuals\",\n",
    "    ),\n",
    "    \"band_gap_ev\": (\"Band Gap [eV] - Residual Errors\", \"Density of Residuals\"),\n",
    "    \"energy_per_atom\": (\n",
    "        \"Energy Per Atom [eV] - Residual Errors\",\n",
    "        \"Density of Residuals\",\n",
    "    ),\n",
    "}\n",
    "for target in target_list:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    df = pd.read_csv(pred_path.joinpath(f'{target}_predictions.csv'), header=0)\n",
    "    ax = fig.add_subplot(1, 1, 1)  # Aggiungi subplot\n",
    "    \n",
    "    sns.histplot(\n",
    "        x=df[f'{target}_residual'],\n",
    "        fill=True,\n",
    "        linewidth=1,\n",
    "        kde=False,\n",
    "        stat=\"density\",\n",
    "        color=colors[1],\n",
    "        ax=ax,\n",
    "        bins=int(np.sqrt(len(df[f'{target}_residual'])))\n",
    "    )\n",
    "    \n",
    "    sns.kdeplot(x=df[f'{target}_residual'], linewidth=2, color=colors[0], ax=ax)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(nbins=3))  # Imposta massimo 3 ticks sull'asse x\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=3))  # Imposta massimo 3 ticks sull'asse y\n",
    "    ax.set_xlabel(target_labels[target][0], fontsize=20)\n",
    "    ax.set_ylabel(target_labels[target][1], fontsize=20)\n",
    "    plt.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path.joinpath(f\"{target}_residual.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\", color=[31/255,44/255,73/255])\n",
    "plt.yticks(pos, np.array(features_list)[sorted_idx], fontsize=20)\n",
    "plt.xticks([0,0.2,0.4,0.6],fontsize=20)\n",
    "result = permutation_importance(\n",
    "    model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "#plt.subplot(1, 2, 2)\n",
    "# plt.boxplot(\n",
    "#     result.importances[sorted_idx].T,\n",
    "#     vert=False,\n",
    "#     labels=np.array(features_list)[sorted_idx],\n",
    "# )\n",
    "#plt.title(\"Permutation Importance (test set)\")\n",
    "\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"features_imp\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_gdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
